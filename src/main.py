# ì „ì²´ íŒŒì´í”„ë¼ì¸ ì œì–´ (Run)

# src/main.py

from .embedder import BGEEmbedder
from .config import RAW_CSV_PATH, PROCESSED_PARQUET_PATH
from .vector_db import load_passage_df, DenseSparseIndex
from .aggregator import aggregate_to_providers
from .reranker import CrossEncoderReranker


def run_build_embeddings():
    embedder = BGEEmbedder()
    embedder.build_vector_parquet(
        input_csv_path=RAW_CSV_PATH,
        output_parquet_path=PROCESSED_PARQUET_PATH,
    )

def run_hybrid_search_example():
    """
    íŒŒì´í”„ë¼ì¸:
    1) Dense + Sparse retrieval (recall)
    2) Cross-Encoder reranking (precision)
    3) Provider aggregation (decision)
    """

    # 1) passage-level parquet ë¡œë“œ
    df = load_passage_df(PROCESSED_PARQUET_PATH)

    # 2) ì¸ë±ìŠ¤ ì´ˆê¸°í™”
    index = DenseSparseIndex(df)

    # 3) Dense ì¸ë±ìŠ¤ êµ¬ì¶•
    index.build_dense_index()

    # 4) ì¿¼ë¦¬
    query = "ê°•ë‚¨ ê·¼ì²˜ê³  ì£¼ì°¨í•  ê³³ì´ ë§ì€ ê³³"

    # 5) Hybrid search (recall ë‹¨ê³„)
    passage_results = index.hybrid_search(
        query_text=query,
        top_k_dense=50,
        top_k_sparse=50,
        k_final=50,
    )


    # 6) ì—…ì²´ ë‹¨ìœ„ë¡œ aggregate 
    # [2ë‹¨ê³„ Retrieval ìœ ë‹›í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ ì£¼ì„ì„ í‘¸ì„¸ìš”. ê·¸ë¦¬ê³  ì•„ë˜ 6ê³¼ 7ë²ˆì„ ì£¼ì„í•˜ì„¸ìš”.]
    # provider_results = aggregate_to_providers(passage_results, top_n_passages=3)

    # 6) Reranker (precision ë‹¨ê³„)
    reranker = CrossEncoderReranker()
    reranked_passages = reranker.rerank(
        query=query,
        passages=passage_results,
        top_k=30,
    )

    # 7) Provider aggregation (decision ë‹¨ê³„)
    provider_results = aggregate_to_providers(
        reranked_passages,
        top_n_passages=3,
    )

    # 8) ì¶œë ¥
    print("\n==============================")
    print(f"ğŸ” Query: {query}")
    print("==============================")

    print("\nğŸ† Provider ranking:")
    for i, prov in enumerate(provider_results, start=1):
        print(f"\n[{i}ìœ„] {prov['hall_name']} (venue_id={prov['venue_id']})")
        print(f"  - score: {prov['score']:.4f}")
        print("  - evidences:")
        for ev in prov["evidences"]:
            snippet = str(ev["text_chunk"]).replace("\n", " ")
            if len(snippet) > 120:
                snippet = snippet[:120] + "..."
            print(
                f"    * [{ev['aspect']}] "
                f"(rerank={ev['rerank_score']:.4f}, "
                f"RRF={ev['rrf_score']:.4f}) "
                f"{snippet}"
            )

if __name__ == "__main__":
    
    # run_build_embeddings() # ì´ˆê¸° ë–„ í•œë²ˆë§Œ
    run_hybrid_search_example()
    
    # 1) rawë°ì´í„° ì„ë² ë”©
    # 2) ChromaDB ì ì¬
    # 3) Hybrid Search
    # 4) Reranker
    # 5) Aggregator
    
    
